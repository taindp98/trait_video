{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "papermill": {
     "duration": 1.370546,
     "end_time": "2020-11-07T08:07:00.280957",
     "exception": false,
     "start_time": "2020-11-07T08:06:58.910411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time, math\n",
    "import argparse, random\n",
    "from math import exp\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.backends import cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as tfs\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.transforms import functional as FF\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import vgg16\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from noise import pnoise3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from ffa_net import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T08:07:00.694201Z",
     "iopub.status.busy": "2020-11-07T08:07:00.692509Z",
     "iopub.status.idle": "2020-11-07T08:07:00.698395Z",
     "shell.execute_reply": "2020-11-07T08:07:00.697379Z"
    },
    "papermill": {
     "duration": 0.374648,
     "end_time": "2020-11-07T08:07:00.698504",
     "exception": false,
     "start_time": "2020-11-07T08:07:00.323856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of training steps\n",
    "steps = 20000\n",
    "# Device name\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# resume Training\n",
    "resume = False\n",
    "# number of evaluation steps\n",
    "eval_step = 5000\n",
    "# learning rate\n",
    "learning_rate = 0.0001\n",
    "# pre-trained model directory\n",
    "pretrained_model_dir = '../input/ffa-net-for-single-image-dehazing-pytorch/trained_models/'\n",
    "# directory to save models to\n",
    "model_dir = './trained_models/'\n",
    "# train data\n",
    "trainset = 'its_train'\n",
    "# test data\n",
    "testset = 'its_test'\n",
    "# model to be used\n",
    "network = 'ffa'\n",
    "# residual_groups\n",
    "gps = 3\n",
    "# residual_blocks\n",
    "blocks = 12\n",
    "# batch size\n",
    "bs = 1\n",
    "# crop image\n",
    "crop = True\n",
    "# Takes effect when crop = True\n",
    "crop_size = 240\n",
    "# No lr cos schedule\n",
    "no_lr_sche = True\n",
    "# perceptual loss\n",
    "perloss = True\n",
    "    \n",
    "crop_size='whole_img'\n",
    "if crop:\n",
    "    crop_size = crop_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to your 'data' folder\n",
    "its_train_path = '../input/indoor-training-set-its-residestandard'\n",
    "its_test_path = '../input/synthetic-objective-testing-set-sots-reside/indoor'\n",
    "\n",
    "ITS_train_loader = DataLoader(dataset=RESIDE_Dataset(its_train_path, train=True, size=crop_size), batch_size=bs, shuffle=True)\n",
    "ITS_test_loader = DataLoader(dataset=RESIDE_Dataset(its_test_path, train=False, size='whole img'), batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014679,
     "end_time": "2020-11-07T08:07:01.417104",
     "exception": false,
     "start_time": "2020-11-07T08:07:01.402425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define Train / Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T08:07:01.470449Z",
     "iopub.status.busy": "2020-11-07T08:07:01.460001Z",
     "iopub.status.idle": "2020-11-07T08:07:01.567826Z",
     "shell.execute_reply": "2020-11-07T08:07:01.568338Z"
    },
    "papermill": {
     "duration": 0.136551,
     "end_time": "2020-11-07T08:07:01.568481",
     "exception": false,
     "start_time": "2020-11-07T08:07:01.431930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_dir : logs/its_train_ffa_3_12\n",
      "model_name: its_train_ffa_3_12\n"
     ]
    }
   ],
   "source": [
    "print('log_dir :', log_dir)\n",
    "print('model_name:', model_name)\n",
    "\n",
    "models_ = {'ffa': FFA(gps = gps, blocks = blocks)}\n",
    "loaders_ = {'its_train': ITS_train_loader, 'its_test': ITS_test_loader}\n",
    "# loaders_ = {'its_train': ITS_train_loader, 'its_test': ITS_test_loader, 'ots_train': OTS_train_loader, 'ots_test': OTS_test_loader}\n",
    "start_time = time.time()\n",
    "T = steps\n",
    "\n",
    "def train(net, loader_train, loader_test, optim, criterion):\n",
    "    losses = []\n",
    "    start_step = 0\n",
    "    max_ssim = max_psnr = 0\n",
    "    ssims, psnrs = [], []\n",
    "    if resume and os.path.exists(pretrained_model_dir):\n",
    "        print(f'resume from {pretrained_model_dir}')\n",
    "        ckp = torch.load(pretrained_model_dir)\n",
    "        losses = ckp['losses']\n",
    "        net.load_state_dict(ckp['model'])\n",
    "        start_step = ckp['step']\n",
    "        max_ssim = ckp['max_ssim']\n",
    "        max_psnr = ckp['max_psnr']\n",
    "        psnrs = ckp['psnrs']\n",
    "        ssims = ckp['ssims']\n",
    "        print(f'Resuming training from step: {start_step} ***')\n",
    "    else :\n",
    "        print('Training from scratch *** ')\n",
    "    for step in range(start_step+1, steps+1):\n",
    "        net.train()\n",
    "        lr = learning_rate\n",
    "        if not no_lr_sche:\n",
    "            lr = lr_schedule_cosdecay(step,T)\n",
    "            for param_group in optim.param_groups:\n",
    "                param_group[\"lr\"] = lr\n",
    "        x, y = next(iter(loader_train))\n",
    "        x = x.to(device); y = y.to(device)\n",
    "        out = net(x)\n",
    "        loss = criterion[0](out,y)\n",
    "        if perloss:\n",
    "            loss2 = criterion[1](out,y)\n",
    "            loss = loss + 0.04*loss2\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "        print(f'\\rtrain loss: {loss.item():.5f} | step: {step}/{steps} | lr: {lr :.7f} | time_used: {(time.time()-start_time)/60 :.1f}',end='',flush=True)\n",
    "\n",
    "        if step % eval_step ==0 :\n",
    "            with torch.no_grad():\n",
    "                ssim_eval, psnr_eval = test(net, loader_test, max_psnr, max_ssim, step)\n",
    "            print(f'\\nstep: {step} | ssim: {ssim_eval:.4f} | psnr: {psnr_eval:.4f}')\n",
    "\n",
    "            ssims.append(ssim_eval)\n",
    "            psnrs.append(psnr_eval)\n",
    "            if ssim_eval > max_ssim and psnr_eval > max_psnr :\n",
    "                max_ssim = max(max_ssim,ssim_eval)\n",
    "                max_psnr = max(max_psnr,psnr_eval)\n",
    "                torch.save({\n",
    "                            'step': step,\n",
    "                            'max_psnr': max_psnr,\n",
    "                            'max_ssim': max_ssim,\n",
    "                            'ssims': ssims,\n",
    "                            'psnrs': psnrs,\n",
    "                            'losses': losses,\n",
    "                            'model': net.state_dict()\n",
    "                }, model_dir)\n",
    "                print(f'\\n model saved at step : {step} | max_psnr: {max_psnr:.4f} | max_ssim: {max_ssim:.4f}')\n",
    "\n",
    "    np.save(f'./numpy_files/{model_name}_{steps}_losses.npy',losses)\n",
    "    np.save(f'./numpy_files/{model_name}_{steps}_ssims.npy',ssims)\n",
    "    np.save(f'./numpy_files/{model_name}_{steps}_psnrs.npy',psnrs)\n",
    "\n",
    "def test(net, loader_test, max_psnr, max_ssim, step):\n",
    "    net.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    ssims, psnrs = [], []\n",
    "    for i, (inputs, targets) in enumerate(loader_test):\n",
    "        inputs = inputs.to(device); targets = targets.to(device)\n",
    "        pred = net(inputs)\n",
    "        # # print(pred)\n",
    "        # tfs.ToPILImage()(torch.squeeze(targets.cpu())).save('111.png')\n",
    "        # vutils.save_image(targets.cpu(),'target.png')\n",
    "        # vutils.save_image(pred.cpu(),'pred.png')\n",
    "        ssim1 = ssim(pred, targets).item()\n",
    "        psnr1 = psnr(pred, targets)\n",
    "        ssims.append(ssim1)\n",
    "        psnrs.append(psnr1)\n",
    "\n",
    "    return np.mean(ssims) ,np.mean(psnrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015677,
     "end_time": "2020-11-07T08:07:01.600081",
     "exception": false,
     "start_time": "2020-11-07T08:07:01.584404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train FFA-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T08:07:01.646372Z",
     "iopub.status.busy": "2020-11-07T08:07:01.645638Z",
     "iopub.status.idle": "2020-11-07T15:09:13.977633Z",
     "shell.execute_reply": "2020-11-07T15:09:13.978590Z"
    },
    "papermill": {
     "duration": 25332.363167,
     "end_time": "2020-11-07T15:09:13.978866",
     "exception": false,
     "start_time": "2020-11-07T08:07:01.615699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6720f31ffb43a3a32c1d7ed912c819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training from scratch *** \n",
      "train loss: 0.10126 | step: 5000/20000 | lr: 0.0001000 | time_used: 103.0\n",
      "step: 5000 | ssim: 0.8149 | psnr: 19.5125\n",
      "\n",
      " model saved at step : 5000 | max_psnr: 19.5125 | max_ssim: 0.8149\n",
      "train loss: 0.05416 | step: 10000/20000 | lr: 0.0001000 | time_used: 208.3\n",
      "step: 10000 | ssim: 0.8526 | psnr: 20.2081\n",
      "\n",
      " model saved at step : 10000 | max_psnr: 20.2081 | max_ssim: 0.8526\n",
      "train loss: 0.04772 | step: 15000/20000 | lr: 0.0001000 | time_used: 313.8\n",
      "step: 15000 | ssim: 0.8572 | psnr: 20.8563\n",
      "\n",
      " model saved at step : 15000 | max_psnr: 20.8563 | max_ssim: 0.8572\n",
      "train loss: 0.06030 | step: 20000/20000 | lr: 0.0001000 | time_used: 419.2\n",
      "step: 20000 | ssim: 0.8892 | psnr: 23.1375\n",
      "\n",
      " model saved at step : 20000 | max_psnr: 23.1375 | max_ssim: 0.8892\n",
      "CPU times: user 4h 25min 5s, sys: 2h 27min 3s, total: 6h 52min 9s\n",
      "Wall time: 7h 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "loader_train = loaders_[trainset]\n",
    "loader_test = loaders_[testset]\n",
    "net = models_[network]\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "criterion = []\n",
    "criterion.append(nn.L1Loss().to(device))\n",
    "if perloss:\n",
    "    vgg_model = vgg16(pretrained=True).features[:16]\n",
    "    vgg_model = vgg_model.to(device)\n",
    "    for param in vgg_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    criterion.append(PerLoss(vgg_model).to(device))\n",
    "optimizer = optim.Adam(params = filter(lambda x: x.requires_grad, net.parameters()), lr=learning_rate, betas=(0.9,0.999), eps=1e-08)\n",
    "optimizer.zero_grad()\n",
    "train(net, loader_train, loader_test, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 7.646212,
     "end_time": "2020-11-07T15:09:30.064130",
     "exception": false,
     "start_time": "2020-11-07T15:09:22.417918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Test FFA-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T15:09:46.133115Z",
     "iopub.status.busy": "2020-11-07T15:09:46.131953Z",
     "iopub.status.idle": "2020-11-07T15:15:56.925237Z",
     "shell.execute_reply": "2020-11-07T15:15:56.924347Z"
    },
    "papermill": {
     "duration": 379.393588,
     "end_time": "2020-11-07T15:15:56.925368",
     "exception": false,
     "start_time": "2020-11-07T15:09:37.531780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_dir: pred_FFA_its/\n"
     ]
    }
   ],
   "source": [
    "# its or ots\n",
    "task = 'its'\n",
    "# test imgs folder\n",
    "test_imgs = '../input/synthetic-objective-testing-set-sots-reside/indoor/hazy/'\n",
    "\n",
    "dataset = task\n",
    "img_dir = test_imgs\n",
    "\n",
    "output_dir = f'pred_FFA_{dataset}/'\n",
    "print(\"pred_dir:\",output_dir)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "ckp = torch.load(model_dir, map_location=device)\n",
    "net = FFA(gps=gps, blocks=blocks)\n",
    "net = nn.DataParallel(net)\n",
    "net.load_state_dict(ckp['model'])\n",
    "net.eval()\n",
    "\n",
    "for im in os.listdir(img_dir):\n",
    "    haze = Image.open(img_dir+im)\n",
    "    haze1 = tfs.Compose([\n",
    "        tfs.ToTensor(),\n",
    "        tfs.Normalize(mean=[0.64, 0.6, 0.58],std=[0.14,0.15, 0.152])\n",
    "    ])(haze)[None,::]\n",
    "    haze_no = tfs.ToTensor()(haze)[None,::]\n",
    "    with torch.no_grad():\n",
    "        pred = net(haze1)\n",
    "    ts = torch.squeeze(pred.clamp(0,1).cpu())\n",
    "    # tensorShow([haze_no, pred.clamp(0,1).cpu()],['haze', 'pred'])\n",
    "    \n",
    "    haze_no = make_grid(haze_no, nrow=1, normalize=True)\n",
    "    ts = make_grid(ts, nrow=1, normalize=True)\n",
    "    image_grid = torch.cat((haze_no, ts), -1)\n",
    "    vutils.save_image(image_grid, output_dir+im.split('.')[0]+'_FFA.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "papermill": {
   "duration": 25751.020388,
   "end_time": "2020-11-07T15:16:05.952699",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-07T08:06:54.932311",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "16e6236d7c18452fbce723dd4d8a0905": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1aaac943aea64897a69c51ab9b6db16a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "224948e91b7e4a34ab06e0b5efe459a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1aaac943aea64897a69c51ab9b6db16a",
       "max": 553433881,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_80181e42b1f44351baa55d1bea106231",
       "value": 553433881
      }
     },
     "334d0952574d408790df496eb3cd3d88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_16e6236d7c18452fbce723dd4d8a0905",
       "placeholder": "​",
       "style": "IPY_MODEL_74636338d0fd4e5ea56bf3685cae48b9",
       "value": " 528M/528M [1:45:47&lt;00:00, 87.2kB/s]"
      }
     },
     "73cb8ba83f0042eeb230312d1b7ca2f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74636338d0fd4e5ea56bf3685cae48b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "80181e42b1f44351baa55d1bea106231": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "9a6720f31ffb43a3a32c1d7ed912c819": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_224948e91b7e4a34ab06e0b5efe459a5",
        "IPY_MODEL_334d0952574d408790df496eb3cd3d88"
       ],
       "layout": "IPY_MODEL_73cb8ba83f0042eeb230312d1b7ca2f6"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
