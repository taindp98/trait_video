{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time, math\n",
    "import argparse, random\n",
    "from math import exp\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.backends import cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as tfs\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.transforms import functional as FF\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import vgg16\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config['steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T17:30:44.830773Z",
     "iopub.status.busy": "2021-12-07T17:30:44.830421Z",
     "iopub.status.idle": "2021-12-07T17:30:44.898865Z",
     "shell.execute_reply": "2021-12-07T17:30:44.897765Z",
     "shell.execute_reply.started": "2021-12-07T17:30:44.830744Z"
    }
   },
   "outputs": [],
   "source": [
    "# number of training steps\n",
    "steps = 20000\n",
    "# Device name\n",
    "# resume Training\n",
    "resume = False\n",
    "# number of evaluation steps\n",
    "eval_step = 5000\n",
    "# learning rate\n",
    "learning_rate = 0.0001\n",
    "# pre-trained model directory\n",
    "pretrained_model_dir = '../input/ffa-net-for-single-image-dehazing-pytorch/trained_models/'\n",
    "# directory to save models to\n",
    "model_dir = './trained_models/'\n",
    "# train data\n",
    "trainset = 'its_train'\n",
    "# test data\n",
    "testset = 'its_test'\n",
    "# model to be used\n",
    "network = 'ffa'\n",
    "# residual_groups\n",
    "gps = 3\n",
    "# residual_blocks\n",
    "blocks = 12\n",
    "# batch size\n",
    "bs = 1\n",
    "# crop image\n",
    "crop = True\n",
    "# Takes effect when crop = True\n",
    "crop_size = 240\n",
    "# No lr cos schedule\n",
    "no_lr_sche = True\n",
    "# perceptual loss\n",
    "perloss = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = trainset + '_' + network.split('.')[0] + '_' + str(gps) + '_' + str(blocks)\n",
    "pretrained_model_dir = pretrained_model_dir + model_name + '.pk'\n",
    "model_dir = model_dir + model_name + '.pk'\n",
    "log_dir = 'logs/' + model_name\n",
    "\n",
    "if not os.path.exists('trained_models'):\n",
    "    os.mkdir('trained_models')\n",
    "if not os.path.exists('numpy_files'):\n",
    "    os.mkdir('numpy_files')\n",
    "if not os.path.exists('logs'):\n",
    "    os.mkdir('logs')\n",
    "if not os.path.exists('samples'):\n",
    "    os.mkdir('samples')\n",
    "if not os.path.exists(f\"samples/{model_name}\"):\n",
    "    os.mkdir(f'samples/{model_name}')\n",
    "if not os.path.exists(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "    \n",
    "crop_size='whole_img'\n",
    "if crop:\n",
    "    crop_size = crop_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T17:30:53.905698Z",
     "iopub.status.busy": "2021-12-07T17:30:53.905335Z",
     "iopub.status.idle": "2021-12-07T17:30:53.913856Z",
     "shell.execute_reply": "2021-12-07T17:30:53.912744Z",
     "shell.execute_reply.started": "2021-12-07T17:30:53.905667Z"
    }
   },
   "outputs": [],
   "source": [
    "# def tensorShow(tensors,titles=None):\n",
    "#     '''t:BCWH'''\n",
    "#     fig=plt.figure()\n",
    "#     for tensor, title, i in zip(tensors, titles, range(len(tensors))):\n",
    "#         img = make_grid(tensor)\n",
    "#         npimg = img.numpy()\n",
    "#         ax = fig.add_subplot(211+i)\n",
    "#         ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "#         ax.set_title(title)\n",
    "#     plt.show()\n",
    "    \n",
    "# def lr_schedule_cosdecay(t, T, init_lr=learning_rate):\n",
    "#     lr=0.5*(1+math.cos(t*math.pi/T))*init_lr\n",
    "#     return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T17:31:02.210781Z",
     "iopub.status.busy": "2021-12-07T17:31:02.210433Z",
     "iopub.status.idle": "2021-12-07T17:31:02.245422Z",
     "shell.execute_reply": "2021-12-07T17:31:02.244243Z",
     "shell.execute_reply.started": "2021-12-07T17:31:02.210749Z"
    }
   },
   "outputs": [],
   "source": [
    "def default_conv(in_channels, out_channels, kernel_size, bias=True):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size, padding=(kernel_size//2), bias=bias)\n",
    "    \n",
    "    \n",
    "class PALayer(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(PALayer, self).__init__()\n",
    "        self.pa = nn.Sequential(\n",
    "                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channel // 8, 1, 1, padding=0, bias=True),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        y = self.pa(x)\n",
    "        return x * y\n",
    "\n",
    "    \n",
    "class CALayer(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(CALayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.ca = nn.Sequential(\n",
    "                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channel // 8, channel, 1, padding=0, bias=True),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "        y = self.ca(y)\n",
    "        return x * y\n",
    "\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, conv, dim, kernel_size,):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = conv(dim, dim, kernel_size, bias=True)\n",
    "        self.act1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv(dim, dim, kernel_size, bias=True)\n",
    "        self.calayer = CALayer(dim)\n",
    "        self.palayer = PALayer(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.act1(self.conv1(x))\n",
    "        res = res+x \n",
    "        res = self.conv2(res)\n",
    "        res = self.calayer(res)\n",
    "        res = self.palayer(res)\n",
    "        res += x \n",
    "        return res\n",
    "\n",
    "    \n",
    "class Group(nn.Module):\n",
    "    def __init__(self, conv, dim, kernel_size, blocks):\n",
    "        super(Group, self).__init__()\n",
    "        modules = [Block(conv, dim, kernel_size)  for _ in range(blocks)]\n",
    "        modules.append(conv(dim, dim, kernel_size))\n",
    "        self.gp = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.gp(x)\n",
    "        res += x\n",
    "        return res\n",
    "\n",
    "    \n",
    "class FFA(nn.Module):\n",
    "    def __init__(self,gps,blocks,conv=default_conv):\n",
    "        super(FFA, self).__init__()\n",
    "        self.gps = gps\n",
    "        self.dim = 64\n",
    "        kernel_size = 3\n",
    "        pre_process = [conv(3, self.dim, kernel_size)]\n",
    "        assert self.gps==3\n",
    "        self.g1 = Group(conv, self.dim, kernel_size,blocks=blocks)\n",
    "        self.g2 = Group(conv, self.dim, kernel_size,blocks=blocks)\n",
    "        self.g3 = Group(conv, self.dim, kernel_size,blocks=blocks)\n",
    "        self.ca = nn.Sequential(*[\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(self.dim*self.gps,self.dim//16,1,padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(self.dim//16, self.dim*self.gps, 1, padding=0, bias=True),\n",
    "            nn.Sigmoid()\n",
    "            ])\n",
    "        self.palayer = PALayer(self.dim)\n",
    "\n",
    "        post_process = [\n",
    "            conv(self.dim, self.dim, kernel_size),\n",
    "            conv(self.dim, 3, kernel_size)]\n",
    "\n",
    "        self.pre = nn.Sequential(*pre_process)\n",
    "        self.post = nn.Sequential(*post_process)\n",
    "\n",
    "    def forward(self, x1):\n",
    "        x = self.pre(x1)\n",
    "        res1 = self.g1(x)\n",
    "        res2 = self.g2(res1)\n",
    "        res3 = self.g3(res2)\n",
    "        w = self.ca(torch.cat([res1,res2,res3],dim=1))\n",
    "        w = w.view(-1,self.gps, self.dim)[:,:,:,None,None]\n",
    "        out = w[:,0,::] * res1 + w[:,1,::] * res2+w[:,2,::] * res3\n",
    "        out = self.palayer(out)\n",
    "        x = self.post(out)\n",
    "        return x + x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T17:31:08.78528Z",
     "iopub.status.busy": "2021-12-07T17:31:08.784916Z",
     "iopub.status.idle": "2021-12-07T17:31:08.794899Z",
     "shell.execute_reply": "2021-12-07T17:31:08.793973Z",
     "shell.execute_reply.started": "2021-12-07T17:31:08.785247Z"
    }
   },
   "outputs": [],
   "source": [
    "# --- Perceptual loss network  --- #\n",
    "class PerLoss(torch.nn.Module):\n",
    "    def __init__(self, vgg_model):\n",
    "        super(PerLoss, self).__init__()\n",
    "        self.vgg_layers = vgg_model\n",
    "        self.layer_name_mapping = {\n",
    "            '3': \"relu1_2\",\n",
    "            '8': \"relu2_2\",\n",
    "            '15': \"relu3_3\"\n",
    "        }\n",
    "\n",
    "    def output_features(self, x):\n",
    "        output = {}\n",
    "        for name, module in self.vgg_layers._modules.items():\n",
    "            x = module(x)\n",
    "            if name in self.layer_name_mapping:\n",
    "                output[self.layer_name_mapping[name]] = x\n",
    "        return list(output.values())\n",
    "\n",
    "    def forward(self, dehaze, gt):\n",
    "        loss = []\n",
    "        dehaze_features = self.output_features(dehaze)\n",
    "        gt_features = self.output_features(gt)\n",
    "        for dehaze_feature, gt_feature in zip(dehaze_features, gt_features):\n",
    "            loss.append(F.mse_loss(dehaze_feature, gt_feature))\n",
    "\n",
    "        return sum(loss)/len(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSIM / PSNR Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T17:31:11.991512Z",
     "iopub.status.busy": "2021-12-07T17:31:11.991173Z",
     "iopub.status.idle": "2021-12-07T17:31:12.011329Z",
     "shell.execute_reply": "2021-12-07T17:31:12.010407Z",
     "shell.execute_reply.started": "2021-12-07T17:31:11.991481Z"
    }
   },
   "outputs": [],
   "source": [
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
    "    return gauss / gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average=True):\n",
    "    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "def ssim(img1, img2, window_size=11, size_average=True):\n",
    "    img1=torch.clamp(img1,min=0,max=1)\n",
    "    img2=torch.clamp(img2,min=0,max=1)\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)\n",
    "\n",
    "def psnr(pred, gt):\n",
    "    pred=pred.clamp(0,1).cpu().numpy()\n",
    "    gt=gt.clamp(0,1).cpu().numpy()\n",
    "    imdff = pred - gt\n",
    "    rmse = math.sqrt(np.mean(imdff ** 2))\n",
    "    if rmse == 0:\n",
    "        return 100\n",
    "    return 20 * math.log10( 1.0 / rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T17:31:15.990958Z",
     "iopub.status.busy": "2021-12-07T17:31:15.990305Z",
     "iopub.status.idle": "2021-12-07T17:31:16.391423Z",
     "shell.execute_reply": "2021-12-07T17:31:16.390572Z",
     "shell.execute_reply.started": "2021-12-07T17:31:15.990914Z"
    }
   },
   "outputs": [],
   "source": [
    "class RESIDE_Dataset(data.Dataset):\n",
    "    def __init__(self, path, train, size=crop_size, format='.png'):\n",
    "        super(RESIDE_Dataset, self).__init__()\n",
    "        self.size = size\n",
    "        self.train = train\n",
    "        self.format = format\n",
    "        self.haze_imgs_dir = os.listdir(os.path.join(path,'hazy'))\n",
    "        self.haze_imgs = [os.path.join(path, 'hazy', img) for img in self.haze_imgs_dir]\n",
    "        self.clear_dir = os.path.join(path,'clear')\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        haze = Image.open(self.haze_imgs[index])\n",
    "        if isinstance(self.size, int):\n",
    "            while haze.size[0] < self.size or haze.size[1] < self.size :\n",
    "                index = random.randint(0, 20000)\n",
    "                haze = Image.open(self.haze_imgs[index])\n",
    "        img = self.haze_imgs[index]\n",
    "        id = img.split('/')[-1].split('_')[0]\n",
    "        clear_name = id + self.format\n",
    "        clear = Image.open(os.path.join(self.clear_dir, clear_name))\n",
    "        clear = tfs.CenterCrop(haze.size[::-1])(clear)\n",
    "        if not isinstance(self.size, str):\n",
    "            i, j, h, w = tfs.RandomCrop.get_params(haze, output_size=(self.size, self.size))\n",
    "            haze = FF.crop(haze, i, j, h, w)\n",
    "            clear = FF.crop(clear, i, j, h, w)\n",
    "        haze, clear = self.augData(haze.convert(\"RGB\"), clear.convert(\"RGB\") )\n",
    "        return haze, clear\n",
    "    \n",
    "    def augData(self, data, target):\n",
    "        if self.train:\n",
    "            rand_hor = random.randint(0,1)\n",
    "            rand_rot = random.randint(0,3)\n",
    "            data = tfs.RandomHorizontalFlip(rand_hor)(data)\n",
    "            target = tfs.RandomHorizontalFlip(rand_hor)(target)\n",
    "            if rand_rot:\n",
    "                data = FF.rotate(data, 90*rand_rot)\n",
    "                target = FF.rotate(target, 90*rand_rot)\n",
    "        data = tfs.ToTensor()(data)\n",
    "        data = tfs.Normalize(mean=[0.64,0.6,0.58], std=[0.14,0.15,0.152])(data)\n",
    "        target = tfs.ToTensor()(target)\n",
    "        return data, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.haze_imgs)\n",
    "\n",
    "\n",
    "# path to your 'data' folder\n",
    "its_train_path = '../input/indoor-training-set-its-residestandard'\n",
    "its_test_path = '../input/synthetic-objective-testing-set-sots-reside/indoor'\n",
    "\n",
    "ITS_train_loader = DataLoader(dataset=RESIDE_Dataset(its_train_path, train=True, size=crop_size), batch_size=bs, shuffle=True)\n",
    "ITS_test_loader = DataLoader(dataset=RESIDE_Dataset(its_test_path, train=False, size='whole img'), batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Train / Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T17:31:25.241937Z",
     "iopub.status.busy": "2021-12-07T17:31:25.241622Z",
     "iopub.status.idle": "2021-12-07T17:31:25.35242Z",
     "shell.execute_reply": "2021-12-07T17:31:25.351504Z",
     "shell.execute_reply.started": "2021-12-07T17:31:25.241908Z"
    }
   },
   "outputs": [],
   "source": [
    "print('log_dir :', log_dir)\n",
    "print('model_name:', model_name)\n",
    "\n",
    "models_ = {'ffa': FFA(gps = gps, blocks = blocks)}\n",
    "loaders_ = {'its_train': ITS_train_loader, 'its_test': ITS_test_loader}\n",
    "# loaders_ = {'its_train': ITS_train_loader, 'its_test': ITS_test_loader, 'ots_train': OTS_train_loader, 'ots_test': OTS_test_loader}\n",
    "start_time = time.time()\n",
    "T = steps\n",
    "\n",
    "def train(net, loader_train, loader_test, optim, criterion):\n",
    "    losses = []\n",
    "    start_step = 0\n",
    "    max_ssim = max_psnr = 0\n",
    "    ssims, psnrs = [], []\n",
    "    if resume and os.path.exists(pretrained_model_dir):\n",
    "        print(f'resume from {pretrained_model_dir}')\n",
    "        ckp = torch.load(pretrained_model_dir)\n",
    "        losses = ckp['losses']\n",
    "        net.load_state_dict(ckp['model'])\n",
    "        start_step = ckp['step']\n",
    "        max_ssim = ckp['max_ssim']\n",
    "        max_psnr = ckp['max_psnr']\n",
    "        psnrs = ckp['psnrs']\n",
    "        ssims = ckp['ssims']\n",
    "        print(f'Resuming training from step: {start_step} ***')\n",
    "    else :\n",
    "        print('Training from scratch *** ')\n",
    "    for step in range(start_step+1, steps+1):\n",
    "        net.train()\n",
    "        lr = learning_rate\n",
    "        if not no_lr_sche:\n",
    "            lr = lr_schedule_cosdecay(step,T)\n",
    "            for param_group in optim.param_groups:\n",
    "                param_group[\"lr\"] = lr\n",
    "        x, y = next(iter(loader_train))\n",
    "        x = x.to(device); y = y.to(device)\n",
    "        out = net(x)\n",
    "        loss = criterion[0](out,y)\n",
    "        if perloss:\n",
    "            loss2 = criterion[1](out,y)\n",
    "            loss = loss + 0.04*loss2\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "        print(f'\\rtrain loss: {loss.item():.5f} | step: {step}/{steps} | lr: {lr :.7f} | time_used: {(time.time()-start_time)/60 :.1f}',end='',flush=True)\n",
    "\n",
    "        if step % eval_step ==0 :\n",
    "            with torch.no_grad():\n",
    "                ssim_eval, psnr_eval = test(net, loader_test, max_psnr, max_ssim, step)\n",
    "            print(f'\\nstep: {step} | ssim: {ssim_eval:.4f} | psnr: {psnr_eval:.4f}')\n",
    "\n",
    "            ssims.append(ssim_eval)\n",
    "            psnrs.append(psnr_eval)\n",
    "            if ssim_eval > max_ssim and psnr_eval > max_psnr :\n",
    "                max_ssim = max(max_ssim,ssim_eval)\n",
    "                max_psnr = max(max_psnr,psnr_eval)\n",
    "                torch.save({\n",
    "                            'step': step,\n",
    "                            'max_psnr': max_psnr,\n",
    "                            'max_ssim': max_ssim,\n",
    "                            'ssims': ssims,\n",
    "                            'psnrs': psnrs,\n",
    "                            'losses': losses,\n",
    "                            'model': net.state_dict()\n",
    "                }, model_dir)\n",
    "                print(f'\\n model saved at step : {step} | max_psnr: {max_psnr:.4f} | max_ssim: {max_ssim:.4f}')\n",
    "\n",
    "    np.save(f'./numpy_files/{model_name}_{steps}_losses.npy',losses)\n",
    "    np.save(f'./numpy_files/{model_name}_{steps}_ssims.npy',ssims)\n",
    "    np.save(f'./numpy_files/{model_name}_{steps}_psnrs.npy',psnrs)\n",
    "\n",
    "def test(net, loader_test, max_psnr, max_ssim, step):\n",
    "    net.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    ssims, psnrs = [], []\n",
    "    for i, (inputs, targets) in enumerate(loader_test):\n",
    "        inputs = inputs.to(device); targets = targets.to(device)\n",
    "        pred = net(inputs)\n",
    "        # # print(pred)\n",
    "        # tfs.ToPILImage()(torch.squeeze(targets.cpu())).save('111.png')\n",
    "        # vutils.save_image(targets.cpu(),'target.png')\n",
    "        # vutils.save_image(pred.cpu(),'pred.png')\n",
    "        ssim1 = ssim(pred, targets).item()\n",
    "        psnr1 = psnr(pred, targets)\n",
    "        ssims.append(ssim1)\n",
    "        psnrs.append(psnr1)\n",
    "        #if (psnr1>max_psnr or ssim1 > max_ssim) and s :\n",
    "#             ts=vutils.make_grid([torch.squeeze(inputs.cpu()),torch.squeeze(targets.cpu()),torch.squeeze(pred.clamp(0,1).cpu())])\n",
    "#             vutils.save_image(ts,f'samples/{model_name}/{step}_{psnr1:.4}_{ssim1:.4}.png')\n",
    "#             s=False\n",
    "    return np.mean(ssims) ,np.mean(psnrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train FFA-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-07T17:31:41.266615Z",
     "iopub.status.busy": "2021-12-07T17:31:41.266238Z",
     "iopub.status.idle": "2021-12-08T00:33:17.469003Z",
     "shell.execute_reply": "2021-12-08T00:33:17.468102Z",
     "shell.execute_reply.started": "2021-12-07T17:31:41.266582Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "loader_train = loaders_[trainset]\n",
    "loader_test = loaders_[testset]\n",
    "net = models_[network]\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "criterion = []\n",
    "criterion.append(nn.L1Loss().to(device))\n",
    "if perloss:\n",
    "    vgg_model = vgg16(pretrained=True).features[:16]\n",
    "    vgg_model = vgg_model.to(device)\n",
    "    for param in vgg_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    criterion.append(PerLoss(vgg_model).to(device))\n",
    "optimizer = optim.Adam(params = filter(lambda x: x.requires_grad, net.parameters()), lr=learning_rate, betas=(0.9,0.999), eps=1e-08)\n",
    "optimizer.zero_grad()\n",
    "train(net, loader_train, loader_test, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test FFA-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# its or ots\n",
    "task = 'its'\n",
    "# test imgs folder\n",
    "test_imgs = '../input/synthetic-objective-testing-set-sots-reside/indoor/hazy/'\n",
    "\n",
    "dataset = task\n",
    "img_dir = test_imgs\n",
    "\n",
    "output_dir = f'pred_FFA_{dataset}/'\n",
    "print(\"pred_dir:\",output_dir)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "ckp = torch.load(model_dir, map_location=device)\n",
    "net = FFA(gps=gps, blocks=blocks)\n",
    "net = nn.DataParallel(net)\n",
    "net.load_state_dict(ckp['model'])\n",
    "net.eval()\n",
    "\n",
    "for im in os.listdir(img_dir):\n",
    "    haze = Image.open(img_dir+im)\n",
    "    haze1 = tfs.Compose([\n",
    "        tfs.ToTensor(),\n",
    "        tfs.Normalize(mean=[0.64, 0.6, 0.58],std=[0.14,0.15, 0.152])\n",
    "    ])(haze)[None,::]\n",
    "    haze_no = tfs.ToTensor()(haze)[None,::]\n",
    "    with torch.no_grad():\n",
    "        pred = net(haze1)\n",
    "    ts = torch.squeeze(pred.clamp(0,1).cpu())\n",
    "    # tensorShow([haze_no, pred.clamp(0,1).cpu()],['haze', 'pred'])\n",
    "    \n",
    "    haze_no = make_grid(haze_no, nrow=1, normalize=True)\n",
    "    ts = make_grid(ts, nrow=1, normalize=True)\n",
    "    image_grid = torch.cat((haze_no, ts), -1)\n",
    "    vutils.save_image(image_grid, output_dir+im.split('.')[0]+'_FFA.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
