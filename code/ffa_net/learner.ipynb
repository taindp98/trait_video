{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-07T08:06:58.934018Z",
     "iopub.status.busy": "2020-11-07T08:06:58.933376Z",
     "iopub.status.idle": "2020-11-07T08:07:00.280825Z",
     "shell.execute_reply": "2020-11-07T08:07:00.280223Z"
    },
    "papermill": {
     "duration": 1.370546,
     "end_time": "2020-11-07T08:07:00.280957",
     "exception": false,
     "start_time": "2020-11-07T08:06:58.910411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import time, math\n",
    "import argparse, random\n",
    "from math import exp\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.backends import cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as tfs\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.transforms import functional as FF\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import vgg16\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T08:07:00.694201Z",
     "iopub.status.busy": "2020-11-07T08:07:00.692509Z",
     "iopub.status.idle": "2020-11-07T08:07:00.698395Z",
     "shell.execute_reply": "2020-11-07T08:07:00.697379Z"
    },
    "papermill": {
     "duration": 0.374648,
     "end_time": "2020-11-07T08:07:00.698504",
     "exception": false,
     "start_time": "2020-11-07T08:07:00.323856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of training steps\n",
    "steps = 20000\n",
    "# Device name\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# resume Training\n",
    "resume = False\n",
    "# number of evaluation steps\n",
    "eval_step = 5000\n",
    "# learning rate\n",
    "learning_rate = 0.0001\n",
    "# pre-trained model directory\n",
    "pretrained_model_dir = '../input/ffa-net-for-single-image-dehazing-pytorch/trained_models/'\n",
    "# directory to save models to\n",
    "model_dir = './trained_models/'\n",
    "# train data\n",
    "trainset = 'its_train'\n",
    "# test data\n",
    "testset = 'its_test'\n",
    "# model to be used\n",
    "network = 'ffa'\n",
    "# residual_groups\n",
    "gps = 3\n",
    "# residual_blocks\n",
    "blocks = 12\n",
    "# batch size\n",
    "bs = 1\n",
    "# crop image\n",
    "crop = True\n",
    "# Takes effect when crop = True\n",
    "crop_size = 240\n",
    "# No lr cos schedule\n",
    "no_lr_sche = True\n",
    "# perceptual loss\n",
    "perloss = True\n",
    "\n",
    "model_name = trainset + '_' + network.split('.')[0] + '_' + str(gps) + '_' + str(blocks)\n",
    "pretrained_model_dir = pretrained_model_dir + model_name + '.pk'\n",
    "model_dir = model_dir + model_name + '.pk'\n",
    "log_dir = 'logs/' + model_name\n",
    "\n",
    "if not os.path.exists('trained_models'):\n",
    "    os.mkdir('trained_models')\n",
    "if not os.path.exists('numpy_files'):\n",
    "    os.mkdir('numpy_files')\n",
    "if not os.path.exists('logs'):\n",
    "    os.mkdir('logs')\n",
    "if not os.path.exists('samples'):\n",
    "    os.mkdir('samples')\n",
    "if not os.path.exists(f\"samples/{model_name}\"):\n",
    "    os.mkdir(f'samples/{model_name}')\n",
    "if not os.path.exists(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "    \n",
    "crop_size='whole_img'\n",
    "if crop:\n",
    "    crop_size = crop_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T08:07:00.765639Z",
     "iopub.status.busy": "2020-11-07T08:07:00.764876Z",
     "iopub.status.idle": "2020-11-07T08:07:00.768408Z",
     "shell.execute_reply": "2020-11-07T08:07:00.767886Z"
    },
    "papermill": {
     "duration": 0.027025,
     "end_time": "2020-11-07T08:07:00.768510",
     "exception": false,
     "start_time": "2020-11-07T08:07:00.741485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tensorShow(tensors,titles=None):\n",
    "    '''t:BCWH'''\n",
    "    fig=plt.figure()\n",
    "    for tensor, title, i in zip(tensors, titles, range(len(tensors))):\n",
    "        img = make_grid(tensor)\n",
    "        npimg = img.numpy()\n",
    "        ax = fig.add_subplot(211+i)\n",
    "        ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        ax.set_title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def lr_schedule_cosdecay(t, T, init_lr=learning_rate):\n",
    "    lr=0.5*(1+math.cos(t*math.pi/T))*init_lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014093,
     "end_time": "2020-11-07T08:07:00.826208",
     "exception": false,
     "start_time": "2020-11-07T08:07:00.812115",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T08:07:00.896336Z",
     "iopub.status.busy": "2020-11-07T08:07:00.889187Z",
     "iopub.status.idle": "2020-11-07T08:07:00.898499Z",
     "shell.execute_reply": "2020-11-07T08:07:00.898959Z"
    },
    "papermill": {
     "duration": 0.05851,
     "end_time": "2020-11-07T08:07:00.899095",
     "exception": false,
     "start_time": "2020-11-07T08:07:00.840585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def default_conv(in_channels, out_channels, kernel_size, bias=True):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size, padding=(kernel_size//2), bias=bias)\n",
    "    \n",
    "    \n",
    "class PALayer(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(PALayer, self).__init__()\n",
    "        self.pa = nn.Sequential(\n",
    "                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channel // 8, 1, 1, padding=0, bias=True),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        y = self.pa(x)\n",
    "        return x * y\n",
    "\n",
    "    \n",
    "class CALayer(nn.Module):\n",
    "    def __init__(self, channel):\n",
    "        super(CALayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.ca = nn.Sequential(\n",
    "                nn.Conv2d(channel, channel // 8, 1, padding=0, bias=True),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(channel // 8, channel, 1, padding=0, bias=True),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.avg_pool(x)\n",
    "        y = self.ca(y)\n",
    "        return x * y\n",
    "\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, conv, dim, kernel_size,):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = conv(dim, dim, kernel_size, bias=True)\n",
    "        self.act1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv(dim, dim, kernel_size, bias=True)\n",
    "        self.calayer = CALayer(dim)\n",
    "        self.palayer = PALayer(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.act1(self.conv1(x))\n",
    "        res = res+x \n",
    "        res = self.conv2(res)\n",
    "        res = self.calayer(res)\n",
    "        res = self.palayer(res)\n",
    "        res += x \n",
    "        return res\n",
    "\n",
    "    \n",
    "class Group(nn.Module):\n",
    "    def __init__(self, conv, dim, kernel_size, blocks):\n",
    "        super(Group, self).__init__()\n",
    "        modules = [Block(conv, dim, kernel_size)  for _ in range(blocks)]\n",
    "        modules.append(conv(dim, dim, kernel_size))\n",
    "        self.gp = nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = self.gp(x)\n",
    "        res += x\n",
    "        return res\n",
    "\n",
    "    \n",
    "class FFA(nn.Module):\n",
    "    def __init__(self,gps,blocks,conv=default_conv):\n",
    "        super(FFA, self).__init__()\n",
    "        self.gps = gps\n",
    "        self.dim = 64\n",
    "        kernel_size = 3\n",
    "        pre_process = [conv(3, self.dim, kernel_size)]\n",
    "        assert self.gps==3\n",
    "        self.g1 = Group(conv, self.dim, kernel_size,blocks=blocks)\n",
    "        self.g2 = Group(conv, self.dim, kernel_size,blocks=blocks)\n",
    "        self.g3 = Group(conv, self.dim, kernel_size,blocks=blocks)\n",
    "        self.ca = nn.Sequential(*[\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(self.dim*self.gps,self.dim//16,1,padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(self.dim//16, self.dim*self.gps, 1, padding=0, bias=True),\n",
    "            nn.Sigmoid()\n",
    "            ])\n",
    "        self.palayer = PALayer(self.dim)\n",
    "\n",
    "        post_process = [\n",
    "            conv(self.dim, self.dim, kernel_size),\n",
    "            conv(self.dim, 3, kernel_size)]\n",
    "\n",
    "        self.pre = nn.Sequential(*pre_process)\n",
    "        self.post = nn.Sequential(*post_process)\n",
    "\n",
    "    def forward(self, x1):\n",
    "        x = self.pre(x1)\n",
    "        res1 = self.g1(x)\n",
    "        res2 = self.g2(res1)\n",
    "        res3 = self.g3(res2)\n",
    "        w = self.ca(torch.cat([res1,res2,res3],dim=1))\n",
    "        w = w.view(-1,self.gps, self.dim)[:,:,:,None,None]\n",
    "        out = w[:,0,::] * res1 + w[:,1,::] * res2+w[:,2,::] * res3\n",
    "        out = self.palayer(out)\n",
    "        x = self.post(out)\n",
    "        return x + x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015069,
     "end_time": "2020-11-07T08:07:00.928724",
     "exception": false,
     "start_time": "2020-11-07T08:07:00.913655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Perceptual Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T08:07:00.971820Z",
     "iopub.status.busy": "2020-11-07T08:07:00.969880Z",
     "iopub.status.idle": "2020-11-07T08:07:00.972531Z",
     "shell.execute_reply": "2020-11-07T08:07:00.973021Z"
    },
    "papermill": {
     "duration": 0.028963,
     "end_time": "2020-11-07T08:07:00.973140",
     "exception": false,
     "start_time": "2020-11-07T08:07:00.944177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Perceptual loss network  --- #\n",
    "class PerLoss(torch.nn.Module):\n",
    "    def __init__(self, vgg_model):\n",
    "        super(PerLoss, self).__init__()\n",
    "        self.vgg_layers = vgg_model\n",
    "        self.layer_name_mapping = {\n",
    "            '3': \"relu1_2\",\n",
    "            '8': \"relu2_2\",\n",
    "            '15': \"relu3_3\"\n",
    "        }\n",
    "\n",
    "    def output_features(self, x):\n",
    "        output = {}\n",
    "        for name, module in self.vgg_layers._modules.items():\n",
    "            x = module(x)\n",
    "            if name in self.layer_name_mapping:\n",
    "                output[self.layer_name_mapping[name]] = x\n",
    "        return list(output.values())\n",
    "\n",
    "    def forward(self, dehaze, gt):\n",
    "        loss = []\n",
    "        dehaze_features = self.output_features(dehaze)\n",
    "        gt_features = self.output_features(gt)\n",
    "        for dehaze_feature, gt_feature in zip(dehaze_features, gt_features):\n",
    "            loss.append(F.mse_loss(dehaze_feature, gt_feature))\n",
    "\n",
    "        return sum(loss)/len(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017513,
     "end_time": "2020-11-07T08:07:01.005343",
     "exception": false,
     "start_time": "2020-11-07T08:07:00.987830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### SSIM / PSNR Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T08:07:01.053619Z",
     "iopub.status.busy": "2020-11-07T08:07:01.052732Z",
     "iopub.status.idle": "2020-11-07T08:07:01.063521Z",
     "shell.execute_reply": "2020-11-07T08:07:01.063048Z"
    },
    "papermill": {
     "duration": 0.042461,
     "end_time": "2020-11-07T08:07:01.063618",
     "exception": false,
     "start_time": "2020-11-07T08:07:01.021157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
    "    return gauss / gauss.sum()\n",
    "\n",
    "def create_window(window_size, channel):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = Variable(_2D_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window\n",
    "\n",
    "def _ssim(img1, img2, window, window_size, channel, size_average=True):\n",
    "    mu1 = F.conv2d(img1, window, padding=window_size // 2, groups=channel)\n",
    "    mu2 = F.conv2d(img2, window, padding=window_size // 2, groups=channel)\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size // 2, groups=channel) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size // 2, groups=channel) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=window_size // 2, groups=channel) - mu1_mu2\n",
    "    C1 = 0.01 ** 2\n",
    "    C2 = 0.03 ** 2\n",
    "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "def ssim(img1, img2, window_size=11, size_average=True):\n",
    "    img1=torch.clamp(img1,min=0,max=1)\n",
    "    img2=torch.clamp(img2,min=0,max=1)\n",
    "    (_, channel, _, _) = img1.size()\n",
    "    window = create_window(window_size, channel)\n",
    "    if img1.is_cuda:\n",
    "        window = window.cuda(img1.get_device())\n",
    "    window = window.type_as(img1)\n",
    "    return _ssim(img1, img2, window, window_size, channel, size_average)\n",
    "\n",
    "def psnr(pred, gt):\n",
    "    pred=pred.clamp(0,1).cpu().numpy()\n",
    "    gt=gt.clamp(0,1).cpu().numpy()\n",
    "    imdff = pred - gt\n",
    "    rmse = math.sqrt(np.mean(imdff ** 2))\n",
    "    if rmse == 0:\n",
    "        return 100\n",
    "    return 20 * math.log10( 1.0 / rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015783,
     "end_time": "2020-11-07T08:07:01.095136",
     "exception": false,
     "start_time": "2020-11-07T08:07:01.079353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Get Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T08:07:01.142955Z",
     "iopub.status.busy": "2020-11-07T08:07:01.142075Z",
     "iopub.status.idle": "2020-11-07T08:07:01.387121Z",
     "shell.execute_reply": "2020-11-07T08:07:01.385995Z"
    },
    "papermill": {
     "duration": 0.275704,
     "end_time": "2020-11-07T08:07:01.387250",
     "exception": false,
     "start_time": "2020-11-07T08:07:01.111546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RESIDE_Dataset(data.Dataset):\n",
    "    def __init__(self, path, train, size=crop_size, format='.png'):\n",
    "        super(RESIDE_Dataset, self).__init__()\n",
    "        self.size = size\n",
    "        self.train = train\n",
    "        self.format = format\n",
    "        self.haze_imgs_dir = os.listdir(os.path.join(path,'hazy'))\n",
    "        self.haze_imgs = [os.path.join(path, 'hazy', img) for img in self.haze_imgs_dir]\n",
    "        self.clear_dir = os.path.join(path,'clear')\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        haze = Image.open(self.haze_imgs[index])\n",
    "        if isinstance(self.size, int):\n",
    "            while haze.size[0] < self.size or haze.size[1] < self.size :\n",
    "                index = random.randint(0, 20000)\n",
    "                haze = Image.open(self.haze_imgs[index])\n",
    "        img = self.haze_imgs[index]\n",
    "        id = img.split('/')[-1].split('_')[0]\n",
    "        clear_name = id + self.format\n",
    "        clear = Image.open(os.path.join(self.clear_dir, clear_name))\n",
    "        clear = tfs.CenterCrop(haze.size[::-1])(clear)\n",
    "        if not isinstance(self.size, str):\n",
    "            i, j, h, w = tfs.RandomCrop.get_params(haze, output_size=(self.size, self.size))\n",
    "            haze = FF.crop(haze, i, j, h, w)\n",
    "            clear = FF.crop(clear, i, j, h, w)\n",
    "        haze, clear = self.augData(haze.convert(\"RGB\"), clear.convert(\"RGB\") )\n",
    "        return haze, clear\n",
    "    \n",
    "    def augData(self, data, target):\n",
    "        if self.train:\n",
    "            rand_hor = random.randint(0,1)\n",
    "            rand_rot = random.randint(0,3)\n",
    "            data = tfs.RandomHorizontalFlip(rand_hor)(data)\n",
    "            target = tfs.RandomHorizontalFlip(rand_hor)(target)\n",
    "            if rand_rot:\n",
    "                data = FF.rotate(data, 90*rand_rot)\n",
    "                target = FF.rotate(target, 90*rand_rot)\n",
    "        data = tfs.ToTensor()(data)\n",
    "        data = tfs.Normalize(mean=[0.64,0.6,0.58], std=[0.14,0.15,0.152])(data)\n",
    "        target = tfs.ToTensor()(target)\n",
    "        return data, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.haze_imgs)\n",
    "\n",
    "\n",
    "# path to your 'data' folder\n",
    "its_train_path = '../input/indoor-training-set-its-residestandard'\n",
    "its_test_path = '../input/synthetic-objective-testing-set-sots-reside/indoor'\n",
    "\n",
    "ITS_train_loader = DataLoader(dataset=RESIDE_Dataset(its_train_path, train=True, size=crop_size), batch_size=bs, shuffle=True)\n",
    "ITS_test_loader = DataLoader(dataset=RESIDE_Dataset(its_test_path, train=False, size='whole img'), batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014679,
     "end_time": "2020-11-07T08:07:01.417104",
     "exception": false,
     "start_time": "2020-11-07T08:07:01.402425",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Define Train / Test Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T08:07:01.470449Z",
     "iopub.status.busy": "2020-11-07T08:07:01.460001Z",
     "iopub.status.idle": "2020-11-07T08:07:01.567826Z",
     "shell.execute_reply": "2020-11-07T08:07:01.568338Z"
    },
    "papermill": {
     "duration": 0.136551,
     "end_time": "2020-11-07T08:07:01.568481",
     "exception": false,
     "start_time": "2020-11-07T08:07:01.431930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_dir : logs/its_train_ffa_3_12\n",
      "model_name: its_train_ffa_3_12\n"
     ]
    }
   ],
   "source": [
    "print('log_dir :', log_dir)\n",
    "print('model_name:', model_name)\n",
    "\n",
    "models_ = {'ffa': FFA(gps = gps, blocks = blocks)}\n",
    "loaders_ = {'its_train': ITS_train_loader, 'its_test': ITS_test_loader}\n",
    "# loaders_ = {'its_train': ITS_train_loader, 'its_test': ITS_test_loader, 'ots_train': OTS_train_loader, 'ots_test': OTS_test_loader}\n",
    "start_time = time.time()\n",
    "T = steps\n",
    "\n",
    "def train(net, loader_train, loader_test, optim, criterion):\n",
    "    losses = []\n",
    "    start_step = 0\n",
    "    max_ssim = max_psnr = 0\n",
    "    ssims, psnrs = [], []\n",
    "    if resume and os.path.exists(pretrained_model_dir):\n",
    "        print(f'resume from {pretrained_model_dir}')\n",
    "        ckp = torch.load(pretrained_model_dir)\n",
    "        losses = ckp['losses']\n",
    "        net.load_state_dict(ckp['model'])\n",
    "        start_step = ckp['step']\n",
    "        max_ssim = ckp['max_ssim']\n",
    "        max_psnr = ckp['max_psnr']\n",
    "        psnrs = ckp['psnrs']\n",
    "        ssims = ckp['ssims']\n",
    "        print(f'Resuming training from step: {start_step} ***')\n",
    "    else :\n",
    "        print('Training from scratch *** ')\n",
    "    for step in range(start_step+1, steps+1):\n",
    "        net.train()\n",
    "        lr = learning_rate\n",
    "        if not no_lr_sche:\n",
    "            lr = lr_schedule_cosdecay(step,T)\n",
    "            for param_group in optim.param_groups:\n",
    "                param_group[\"lr\"] = lr\n",
    "        x, y = next(iter(loader_train))\n",
    "        x = x.to(device); y = y.to(device)\n",
    "        out = net(x)\n",
    "        loss = criterion[0](out,y)\n",
    "        if perloss:\n",
    "            loss2 = criterion[1](out,y)\n",
    "            loss = loss + 0.04*loss2\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "        print(f'\\rtrain loss: {loss.item():.5f} | step: {step}/{steps} | lr: {lr :.7f} | time_used: {(time.time()-start_time)/60 :.1f}',end='',flush=True)\n",
    "\n",
    "        if step % eval_step ==0 :\n",
    "            with torch.no_grad():\n",
    "                ssim_eval, psnr_eval = test(net, loader_test, max_psnr, max_ssim, step)\n",
    "            print(f'\\nstep: {step} | ssim: {ssim_eval:.4f} | psnr: {psnr_eval:.4f}')\n",
    "\n",
    "            ssims.append(ssim_eval)\n",
    "            psnrs.append(psnr_eval)\n",
    "            if ssim_eval > max_ssim and psnr_eval > max_psnr :\n",
    "                max_ssim = max(max_ssim,ssim_eval)\n",
    "                max_psnr = max(max_psnr,psnr_eval)\n",
    "                torch.save({\n",
    "                            'step': step,\n",
    "                            'max_psnr': max_psnr,\n",
    "                            'max_ssim': max_ssim,\n",
    "                            'ssims': ssims,\n",
    "                            'psnrs': psnrs,\n",
    "                            'losses': losses,\n",
    "                            'model': net.state_dict()\n",
    "                }, model_dir)\n",
    "                print(f'\\n model saved at step : {step} | max_psnr: {max_psnr:.4f} | max_ssim: {max_ssim:.4f}')\n",
    "\n",
    "    np.save(f'./numpy_files/{model_name}_{steps}_losses.npy',losses)\n",
    "    np.save(f'./numpy_files/{model_name}_{steps}_ssims.npy',ssims)\n",
    "    np.save(f'./numpy_files/{model_name}_{steps}_psnrs.npy',psnrs)\n",
    "\n",
    "def test(net, loader_test, max_psnr, max_ssim, step):\n",
    "    net.eval()\n",
    "    torch.cuda.empty_cache()\n",
    "    ssims, psnrs = [], []\n",
    "    for i, (inputs, targets) in enumerate(loader_test):\n",
    "        inputs = inputs.to(device); targets = targets.to(device)\n",
    "        pred = net(inputs)\n",
    "        # # print(pred)\n",
    "        # tfs.ToPILImage()(torch.squeeze(targets.cpu())).save('111.png')\n",
    "        # vutils.save_image(targets.cpu(),'target.png')\n",
    "        # vutils.save_image(pred.cpu(),'pred.png')\n",
    "        ssim1 = ssim(pred, targets).item()\n",
    "        psnr1 = psnr(pred, targets)\n",
    "        ssims.append(ssim1)\n",
    "        psnrs.append(psnr1)\n",
    "        #if (psnr1>max_psnr or ssim1 > max_ssim) and s :\n",
    "#             ts=vutils.make_grid([torch.squeeze(inputs.cpu()),torch.squeeze(targets.cpu()),torch.squeeze(pred.clamp(0,1).cpu())])\n",
    "#             vutils.save_image(ts,f'samples/{model_name}/{step}_{psnr1:.4}_{ssim1:.4}.png')\n",
    "#             s=False\n",
    "    return np.mean(ssims) ,np.mean(psnrs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": 0.015677,
     "end_time": "2020-11-07T08:07:01.600081",
     "exception": false,
     "start_time": "2020-11-07T08:07:01.584404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train FFA-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T08:07:01.646372Z",
     "iopub.status.busy": "2020-11-07T08:07:01.645638Z",
     "iopub.status.idle": "2020-11-07T15:09:13.977633Z",
     "shell.execute_reply": "2020-11-07T15:09:13.978590Z"
    },
    "papermill": {
     "duration": 25332.363167,
     "end_time": "2020-11-07T15:09:13.978866",
     "exception": false,
     "start_time": "2020-11-07T08:07:01.615699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6720f31ffb43a3a32c1d7ed912c819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training from scratch *** \n",
      "train loss: 0.10126 | step: 5000/20000 | lr: 0.0001000 | time_used: 103.0\n",
      "step: 5000 | ssim: 0.8149 | psnr: 19.5125\n",
      "\n",
      " model saved at step : 5000 | max_psnr: 19.5125 | max_ssim: 0.8149\n",
      "train loss: 0.05416 | step: 10000/20000 | lr: 0.0001000 | time_used: 208.3\n",
      "step: 10000 | ssim: 0.8526 | psnr: 20.2081\n",
      "\n",
      " model saved at step : 10000 | max_psnr: 20.2081 | max_ssim: 0.8526\n",
      "train loss: 0.04772 | step: 15000/20000 | lr: 0.0001000 | time_used: 313.8\n",
      "step: 15000 | ssim: 0.8572 | psnr: 20.8563\n",
      "\n",
      " model saved at step : 15000 | max_psnr: 20.8563 | max_ssim: 0.8572\n",
      "train loss: 0.06030 | step: 20000/20000 | lr: 0.0001000 | time_used: 419.2\n",
      "step: 20000 | ssim: 0.8892 | psnr: 23.1375\n",
      "\n",
      " model saved at step : 20000 | max_psnr: 23.1375 | max_ssim: 0.8892\n",
      "CPU times: user 4h 25min 5s, sys: 2h 27min 3s, total: 6h 52min 9s\n",
      "Wall time: 7h 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "loader_train = loaders_[trainset]\n",
    "loader_test = loaders_[testset]\n",
    "net = models_[network]\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "criterion = []\n",
    "criterion.append(nn.L1Loss().to(device))\n",
    "if perloss:\n",
    "    vgg_model = vgg16(pretrained=True).features[:16]\n",
    "    vgg_model = vgg_model.to(device)\n",
    "    for param in vgg_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    criterion.append(PerLoss(vgg_model).to(device))\n",
    "optimizer = optim.Adam(params = filter(lambda x: x.requires_grad, net.parameters()), lr=learning_rate, betas=(0.9,0.999), eps=1e-08)\n",
    "optimizer.zero_grad()\n",
    "train(net, loader_train, loader_test, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 7.646212,
     "end_time": "2020-11-07T15:09:30.064130",
     "exception": false,
     "start_time": "2020-11-07T15:09:22.417918",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Test FFA-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-07T15:09:46.133115Z",
     "iopub.status.busy": "2020-11-07T15:09:46.131953Z",
     "iopub.status.idle": "2020-11-07T15:15:56.925237Z",
     "shell.execute_reply": "2020-11-07T15:15:56.924347Z"
    },
    "papermill": {
     "duration": 379.393588,
     "end_time": "2020-11-07T15:15:56.925368",
     "exception": false,
     "start_time": "2020-11-07T15:09:37.531780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_dir: pred_FFA_its/\n"
     ]
    }
   ],
   "source": [
    "# its or ots\n",
    "task = 'its'\n",
    "# test imgs folder\n",
    "test_imgs = '../input/synthetic-objective-testing-set-sots-reside/indoor/hazy/'\n",
    "\n",
    "dataset = task\n",
    "img_dir = test_imgs\n",
    "\n",
    "output_dir = f'pred_FFA_{dataset}/'\n",
    "print(\"pred_dir:\",output_dir)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "ckp = torch.load(model_dir, map_location=device)\n",
    "net = FFA(gps=gps, blocks=blocks)\n",
    "net = nn.DataParallel(net)\n",
    "net.load_state_dict(ckp['model'])\n",
    "net.eval()\n",
    "\n",
    "for im in os.listdir(img_dir):\n",
    "    haze = Image.open(img_dir+im)\n",
    "    haze1 = tfs.Compose([\n",
    "        tfs.ToTensor(),\n",
    "        tfs.Normalize(mean=[0.64, 0.6, 0.58],std=[0.14,0.15, 0.152])\n",
    "    ])(haze)[None,::]\n",
    "    haze_no = tfs.ToTensor()(haze)[None,::]\n",
    "    with torch.no_grad():\n",
    "        pred = net(haze1)\n",
    "    ts = torch.squeeze(pred.clamp(0,1).cpu())\n",
    "    # tensorShow([haze_no, pred.clamp(0,1).cpu()],['haze', 'pred'])\n",
    "    \n",
    "    haze_no = make_grid(haze_no, nrow=1, normalize=True)\n",
    "    ts = make_grid(ts, nrow=1, normalize=True)\n",
    "    image_grid = torch.cat((haze_no, ts), -1)\n",
    "    vutils.save_image(image_grid, output_dir+im.split('.')[0]+'_FFA.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "papermill": {
   "duration": 25751.020388,
   "end_time": "2020-11-07T15:16:05.952699",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-07T08:06:54.932311",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "16e6236d7c18452fbce723dd4d8a0905": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1aaac943aea64897a69c51ab9b6db16a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "224948e91b7e4a34ab06e0b5efe459a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1aaac943aea64897a69c51ab9b6db16a",
       "max": 553433881,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_80181e42b1f44351baa55d1bea106231",
       "value": 553433881
      }
     },
     "334d0952574d408790df496eb3cd3d88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_16e6236d7c18452fbce723dd4d8a0905",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_74636338d0fd4e5ea56bf3685cae48b9",
       "value": " 528M/528M [1:45:47&lt;00:00, 87.2kB/s]"
      }
     },
     "73cb8ba83f0042eeb230312d1b7ca2f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74636338d0fd4e5ea56bf3685cae48b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "80181e42b1f44351baa55d1bea106231": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "9a6720f31ffb43a3a32c1d7ed912c819": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_224948e91b7e4a34ab06e0b5efe459a5",
        "IPY_MODEL_334d0952574d408790df496eb3cd3d88"
       ],
       "layout": "IPY_MODEL_73cb8ba83f0042eeb230312d1b7ca2f6"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
